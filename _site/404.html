<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-E00L9PT3V9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-E00L9PT3V9');
  </script>
  <title></title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/404.html">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Zhihan Yang
              </h1>
              <p>I'm a first-year PhD student at <a href="https://www.cs.cornell.edu/">Cornell CS</a>, where I focus on machine learning and specifically generative models.
              </p>
              <p>I have a BA in Mathematics and a BA in Statistics from <a href="https://www.carleton.edu/math/">Carleton College</a>. During those years, I was fortunate to work with <a href="http://www.sethcooper.net/">Seth Cooper</a> on generative models, <a href="https://sites.google.com/site/annanrafferty/">Anna Rafferty</a> on bandits, <a href="https://www.khoury.northeastern.edu/home/camato/">Christopher Amato</a> on deep reinforcement learning, and <a href="https://aloy.rbind.io/">Adam Loy</a> on MCMC algorithms. 
              </p>
              <p>I received the <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/#2023">CRA Outstanding Undergraduate Researcher Award</a>.</p>
              <p style="text-align:center">
                <a href="mailto:zhihany@cs.cornell.edu"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/zhihanyang2022">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=WjinQ20AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/~zy/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:60%" alt="profile photo" src="images/Yang_Zhihan_Photo.jpg">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                Currently, I'm interested in developing principled, controllable and efficient generative models for various modalities.
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/esolm-square.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Scaling Beyond Masked Diffusion Language Models</h3>
              <br>
              Subham Sekhar Sahoo, Jean-Marie Lamercier* , Zhihan Yang*, Justin Deschenaux* (Joint Second Authors), Jingyu Liu, John Thickstun, Ante Jukic

              <br>
              <em>arXiv</em>, 2026
              <br>
              
              <a href="https://arxiv.org/abs/2506.01928">arxiv</a> /
              
              
              
              <a href="https://github.com/s-sahoo/Eso-LMs">code</a> /
              
              
              
              
              <a href="https://s-sahoo.com/Eso-LMs/">website</a> /
              
              
              <a href="https://x.com/zhihanyang_/status/1929979063634145341">twitter</a> /
              
              
              <p></p>
              <p>We study the scaling behavior of masked, interpolating, and uniform-state diffusion language models. I developed the entire SFT pipeline (for AR, MDLM, and Eso-LMs) supporting downstream task evaluation.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/duo_scaling.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Scaling Beyond Masked Diffusion Language Models</h3>
              <br>
              Subham Sekhar Sahoo, Jean-Marie Lamercier*, <strong>Zhihan Yang*</strong>, Justin Deschenaux* (Joint Second Authors), Jingyu Liu, John Thickstun, Ante Jukić

              <br>
              <em>arXiv</em>, 2025
              <br>
              
              <a href="https://arxiv.org/abs/2506.01928">arxiv</a> /
              
              
              
              <a href="https://github.com/s-sahoo/Eso-LMs">code</a> /
              
              
              
              
              <a href="https://s-sahoo.com/scaling-dllms/">website</a> /
              
              
              <a href="https://x.com/zhihanyang_/status/1929979063634145341">twitter</a> /
              
              
              <p></p>
              <p>We demonstrate that uniform-state diffusion could beat masked diffusion on likelihood evaluation benchmarks and GSM8K. I led the full SFT pipeline for AR, MDLM, and Eso-LMs.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/esolm-square.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Esoteric Language Models</h3>
              <br>
              Subham Sekhar Sahoo*, <strong>Zhihan Yang*</strong> (Joint First Authors), Yash Akhauri†, Johnna Liu†, Deepansha Singh†, Zhoujun Cheng† (Joint Second Authors), Zhengzhong Liu, Eric Xing, John Thickstun, Arash Vahdat

              <br>
              <em>arXiv</em>, 2025
              <br>
              
              <a href="https://arxiv.org/abs/2506.01928">arxiv</a> /
              
              
              
              <a href="https://github.com/s-sahoo/Eso-LMs">code</a> /
              
              
              
              
              <a href="https://s-sahoo.com/Eso-LMs/">website</a> /
              
              
              <a href="https://x.com/zhihanyang_/status/1929979063634145341">twitter</a> /
              
              
              <p></p>
              <p>We are the first to propose KV-caching for masked diffusion language models.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/bd3lm.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models</h3>
              <br>
              Marianne Arriola, Aaron Gokaslan, Justin Chiu, <b>Zhihan Yang</b>, Zhixuan Qi, Jiaqi Han, Subham Sahoo, Volodymyr Kuleshov

              <br>
              <em>ICLR (Oral)</em>, 2025
              <br>
              
              <a href="https://openreview.net/forum?id=tyEyYT267x">arxiv</a> /
              
              
              
              <a href="https://github.com/kuleshov-group/bd3lms">code</a> /
              
              
              
              
              <a href="https://m-arriola.com/bd3lms/">website</a> /
              
              
              
              <p></p>
              <p>We introduce a class of block diffusion language models that interpolate between discrete denoising diffusion and autoregressive models.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/adv-bandits-square.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Adversarial Bandits for Drawing Generalizable Conclusions in Non-Adversarial Experiments: An Empirical Study</h3>
              <br>
              <strong>Zhihan Yang</strong>, Shiyue Zhang, Anna Rafferty

              <br>
              <em>EDM (Short Paper)</em>, 2022
              <br>
              
              <a href="https://educationaldatamining.org/edm2022/proceedings/2022.EDM-short-papers.32/2022.EDM-short-papers.32.pdf">arxiv</a> /
              
              
              
              <a href="http://tiny.cc/MABExpDesign">code</a> /
              
              
              
              
              <a href="https://educationaldatamining.org/EDM2022/proceedings/2022.EDM-short-papers.32/">website</a> /
              
              
              
              <p></p>
              <p>We empirically analyse how adversarial bandit algorithms can enhance the reliability of conclusions drawn from large-scale educational experiments.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/hrl-mixed-observability-square.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Hierarchical Reinforcement Learning under Mixed Observability</h3>
              <br>
              Hai Nguyen*, <strong>Zhihan Yang*</strong> (Joint First Authors), Andrea Baisero, Xiao Ma, Robert Platt†, Christopher Amato† (Joint Senior Authors)

              <br>
              <em>WAFR</em>, 2022
              <br>
              
              <a href="https://arxiv.org/abs/2204.00898">arxiv</a> /
              
              
              
              
              
              
              <a href="https://sites.google.com/view/hilmo-wafr">website</a> /
              
              
              
              <p></p>
              <p>We present a hierarchical RL framework that handles mixed observability settings, enabling modular policies that scale to complex robotic tasks.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/robc-square.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Recurrent Off-policy Baselines for Memory-based Continuous Control</h3>
              <br>
              <strong>Zhihan Yang</strong>*, Hai Nguyen* (Joint First Authors)

              <br>
              <em>Deep RL Workshop @ NeurIPS</em>, 2021
              <br>
              
              <a href="https://arxiv.org/abs/2110.12628">arxiv</a> /
              
              
              
              <a href="https://github.com/zhihanyang2022/off-policy-continuous-control">code</a> /
              
              
              
              
              
              
              <p></p>
              <p>We establish strong recurrent off-policy baselines for tasks requiring long-term memory.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/game-level-clustering-square.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Game Level Clustering and Generation using Gaussian Mixture VAEs</h3>
              <br>
              <strong>Zhihan Yang</strong>, Anurag Sarkar, Seth Cooper

              <br>
              <em>AIIDE (Oral)</em>, 2020
              <br>
              
              <a href="https://arxiv.org/abs/2009.09811">arxiv</a> /
              
              
              
              
              
              
              
              
              <p></p>
              <p>We leverage the Gaussian-Mixture VAE framework to cluster game levels in an unsupervised manner and synthesize novel game levels from the learned clusters.</p>

            </td>
          </tr>
          
          
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
              <p>Upcoming.
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>
        <br>
        <br>
        <br>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

